{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOCiG97Ivoq70RTYvNg3v14"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Importing Packages"
      ],
      "metadata": {
        "id": "z7YqmtrTuySo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j8V5_P5cucSy"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import sklearn as skl\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "from scipy import stats"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#data importing \n",
        "\n",
        "data_Set = pd.read_excel('/content/Positive Training .xlsx')\n",
        "\n",
        "\n",
        "holdoutfile_xvals = pd.read_excel('/content/Holdout.Extract (1).xlsx') #holdout file\n",
        "\n",
        "x_idremove = holdoutfile_xvals.drop(labels='id',axis=1) #holdoutfile \n",
        "x_idremove.info\n"
      ],
      "metadata": {
        "id": "wUlchYtV_vFe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Pre-processing"
      ],
      "metadata": {
        "id": "wYWpq62NvU5u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Building a class for data pre-processing"
      ],
      "metadata": {
        "id": "BAIOwYBCXZy1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# building a class for data processing \n",
        "\n",
        "class data_cleaning():\n",
        "  def __init__(self,datafile):\n",
        "    self.datafile = datafile\n",
        "\n",
        "  def missingvals(self): #finding missing values and replacing it with the approiate stat for our model\n",
        "       self.datafile = (self.datafile.fillna(self.datafile.median()))\n",
        "       return self.datafile\n",
        "\n",
        "  def dummy_code(self): #finding qual vars and coding dummay vars \n",
        "       dummy = pd.get_dummies(self.datafile,drop_first=False)\n",
        "       self.datafile = (self.datafile.fillna(self.datafile.mode()))\n",
        "       return dummy\n",
        "\n",
        "\n",
        "  "
      ],
      "metadata": {
        "id": "97f9qfnDGjpV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#applying our class to the dataset\n",
        "clean_data = data_cleaning(data_Set) #for training data \n",
        "clean_data2 = clean_data.missingvals()\n",
        "clean_data3 = clean_data.dummy_code()\n",
        "clean_data3"
      ],
      "metadata": {
        "id": "vA0GWzItJBfA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Correlation Matrix for Numeric data"
      ],
      "metadata": {
        "id": "pzFFxRS0lGij"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index = clean_data3.iloc[:,0:70]\n",
        "\n",
        "mat=index.corr()\n",
        "sns.set(rc = {'figure.figsize':(30,30)})\n",
        "sns.heatmap(mat, annot=True,linewidths=2)\n",
        "plt.show()\n",
        "\n",
        "#clean_data3.iloc[:,0:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "TadyC1wzzwxn",
        "outputId": "89bbd71e-11a6-494f-8fea-17b2b76cc4bc"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-620ff6bb3a1b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclean_data3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m70\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'figure.figsize'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheatmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mannot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlinewidths\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'clean_data3' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training the Log Model "
      ],
      "metadata": {
        "id": "95jLdZHav3Lp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x = clean_data3.drop(columns=['Target var'])\n",
        "\n",
        "\n",
        "y = clean_data3['Target Var']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)\n",
        "\n"
      ],
      "metadata": {
        "id": "FUR7zLRBwAGa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#using weights for unbalanced target var and building our trained model"
      ],
      "metadata": {
        "id": "1JUnJpQeXI_l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import make_classification\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix\n",
        "\n",
        "x, y = make_classification(n_samples=100000, n_features=2, n_informative=2,\n",
        "                           n_redundant=0, n_repeated=0, n_classes=2,\n",
        "                           n_clusters_per_class=1,\n",
        "                           weights=[0.995, 0.005],\n",
        "                           class_sep=0.5, random_state=42)\n",
        "\n",
        "\n",
        "#x,y split and model building\n",
        "x = clean_data3[['Number of signifigant variables']]\n",
        "\n",
        "\n",
        "y = clean_data3['Target var']\n",
        "\n",
        "\n",
        "y \n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)\n",
        "\n",
        "print(X_train.shape,y_train.shape)\n",
        "\n",
        "\n",
        "train_model = LogisticRegression(class_weight='balanced')\n",
        "\n",
        "train_model.fit(X_train,y_train)\n",
        "\n",
        "y_pred=train_model.predict(X_train)\n",
        "\n",
        "conf_matrix=confusion_matrix(y_train,train_model.predict(X_train))"
      ],
      "metadata": {
        "id": "BOOo89N3XH-D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10d4e790-f7f9-4b0d-b879-6df1e7c73df6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(33810, 11) (33810,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#model accuracy\n",
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(y_train,y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6QUSA_o9Z5mD",
        "outputId": "ce4c56b1-268f-4001-cf61-89564b4b8d40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6600709849157054"
            ]
          },
          "metadata": {},
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Area under the ROC curve statistic for training\n",
        "from sklearn import metrics\n",
        "metrics.roc_auc_score(y_train, y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        },
        "id": "ZSXoygVpaJCA",
        "outputId": "d3f7ebab-3fc2-417a-9d5b-8f49270fea73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-5f250d1f43a0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'y_train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# confusion matrix\n",
        "conf_matrix_1=confusion_matrix(y_test,train_model.predict(X_train))\n",
        "\n",
        "print(conf_matrix_1)\n",
        "\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "confusion_train =confusion_matrix(y_train,y_pred)\n",
        "\n",
        "ax= plt.subplot()\n",
        "sns.heatmap(confusion_train, annot=True, fmt='g', ax=ax);  #annot=True to annotate cells, ftm='g' to disable scientific notation\n",
        "\n",
        "# labels, title and ticks\n",
        "ax.set_xlabel('Predicted');ax.set_ylabel('Actual'); \n",
        "ax.set_title('Confusion Matrix'); \n",
        "ax.xaxis.set_ticklabels(['True_Negative', 'True_Positive']); ax.yaxis.set_ticklabels(['False_Negative', 'False Positive']);"
      ],
      "metadata": {
        "id": "YE99rb5obOTO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Regression Ouput for training\n",
        "import statsmodels.api as sm\n",
        "def get_log_Results():\n",
        "  x_featTrain = X_train\n",
        "  results = sm.Logit(y_train,X_train).fit()\n",
        "  print(results.summary())\n",
        "output = get_log_Results()\n",
        "output\n"
      ],
      "metadata": {
        "id": "RyFcOZnuCvBt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Testing the Log model with new data "
      ],
      "metadata": {
        "id": "qCE-cY5RwBIg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_prediction = train_model.predict(X_test) # testing model"
      ],
      "metadata": {
        "id": "lFC8RNJhwGTb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#test the model for accuracy and AUC score"
      ],
      "metadata": {
        "id": "nFyrq15H8e70"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(y_test,y_prediction)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0PXWSP6d8eVp",
        "outputId": "b31b37d4-3b9c-4fef-cc7e-5aa4dfa5828f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7000690131124914"
            ]
          },
          "metadata": {},
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "metrics.roc_auc_score(y_test, y_prediction)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AVaWlwSG8k89",
        "outputId": "2f72e559-637c-4726-ec4b-981fdc561884"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6655639493832373"
            ]
          },
          "metadata": {},
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Confusion Matrix for modeling test accuracy"
      ],
      "metadata": {
        "id": "ljRFFsb9wOEH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "x = confusion_matrix(y_test,y_prediction)\n",
        "\n",
        "\n",
        "ax= plt.subplot()\n",
        "sns.heatmap(x, annot=True, fmt='g', ax=ax);  #annot=True to annotate cells, ftm='g' to disable scientific notation\n",
        "\n",
        "# labels, title and ticks\n",
        "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n",
        "ax.set_title('Confusion Matrix'); \n",
        "ax.xaxis.set_ticklabels(['True_Negative', 'True_Positive']); ax.yaxis.set_ticklabels(['False_Negative', 'False_Positive']);\n"
      ],
      "metadata": {
        "id": "jsVVJkdWwT8G",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "32a00575-3339-4ef8-f6d4-0beff1da7eb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-81de10898989>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_prediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'y_prediction' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "train = classification_report(y_test, train_model.predict(X_test))\n",
        "print(train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bBU2R4SlDjcn",
        "outputId": "d2b3565e-601e-4816-c5b6-54e8d66fd6dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      1.00      0.98     13864\n",
            "           1       0.00      0.00      0.00       626\n",
            "\n",
            "    accuracy                           0.96     14490\n",
            "   macro avg       0.48      0.50      0.49     14490\n",
            "weighted avg       0.92      0.96      0.94     14490\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test = classification_report(y_train, train_model.predict(X_train))\n",
        "\n",
        "print(test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TrY4NhCYEa1f",
        "outputId": "4a988728-35a6-41fa-b337-e912cf21bee9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      1.00      0.98     32318\n",
            "           1       0.00      0.00      0.00      1492\n",
            "\n",
            "    accuracy                           0.96     33810\n",
            "   macro avg       0.48      0.50      0.49     33810\n",
            "weighted avg       0.91      0.96      0.93     33810\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#stepwise log model for var selection"
      ],
      "metadata": {
        "id": "1SLrtQR3-X2l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.api as sm\n",
        "\n",
        "def backward_regression(X, y,\n",
        "                           initial_list=[], \n",
        "                           threshold_in=0.01, \n",
        "                           threshold_out = 0.05, \n",
        "                           verbose=True):\n",
        "    included=list(X.columns)\n",
        "    while True:\n",
        "        changed=False\n",
        "        model = sm.Logit(y, sm.add_constant(pd.DataFrame(X[included]))).fit()\n",
        "        # use all coefs except intercept\n",
        "        pvalues = model.pvalues.iloc[1:]\n",
        "        worst_pval = pvalues.max() # null if pvalues is empty\n",
        "        if worst_pval > threshold_out:\n",
        "            changed=True\n",
        "            worst_feature = pvalues.idxmax()\n",
        "            included.remove(worst_feature)\n",
        "            if verbose:\n",
        "                print('Drop with p-value '.format(worst_feature, worst_pval))\n",
        "        if not changed:\n",
        "            break\n",
        "    return included\n",
        "def get_log_Results():\n",
        "  x_featTrain = x\n",
        "  results = sm.Logit(y_train,X_train).fit()\n",
        "  print(results.summary())\n",
        "\n",
        "output = get_log_Results()\n",
        "output\n",
        "train_forward_step = backward_regression(X_train,y_train)\n",
        "train_forward_step"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NtWv2JLkE_wd",
        "outputId": "2cff9423-e17b-4b96-9980-cc0b1540ff1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimization terminated successfully.\n",
            "         Current function value: 0.574342\n",
            "         Iterations 7\n",
            "                           Logit Regression Results                           \n",
            "==============================================================================\n",
            "Dep. Variable:                hi_flag   No. Observations:                33810\n",
            "Model:                          Logit   Df Residuals:                    33809\n",
            "Method:                           MLE   Df Model:                            0\n",
            "Date:                Thu, 13 Oct 2022   Pseudo R-squ.:                  -2.176\n",
            "Time:                        19:54:29   Log-Likelihood:                -19419.\n",
            "converged:                       True   LL-Null:                       -6114.6\n",
            "Covariance Type:            nonrobust   LLR p-value:                       nan\n",
            "====================================================================================\n",
            "                       coef    std err          z      P>|z|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------------\n",
            "cms_disabled_ind    -2.5817      0.041    -63.169      0.000      -2.662      -2.502\n",
            "====================================================================================\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.178088\n",
            "         Iterations 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/tsa/tsatools.py:142: FutureWarning: In a future version of pandas all arguments of concat except for the argument 'objs' will be keyword-only\n",
            "  x = pd.concat(x[::order], 1)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['cms_disabled_ind']"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    }
  ]
}